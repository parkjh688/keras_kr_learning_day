{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pixelcnn의 사본","provenance":[{"file_id":"https://github.com/keras-team/keras-io/blob/master/examples/generative/ipynb/pixelcnn.ipynb","timestamp":1608128223686}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"2yzxCt2bzdEI"},"source":["# PixelCNN\n","\n","**Author:** [ADMoreau](https://github.com/ADMoreau)<br>\n","**Date created:** 2020/05/17<br>\n","**Last modified:** 2020/05/23<br>\n","**Description:** PixelCNN implemented in Keras.<br>\n","**Translate:** [Junghyun Park](https://github.com/parkjh688)"]},{"cell_type":"markdown","metadata":{"id":"SWxv0LqpzdES"},"source":["## 시작하기\n","\n","PixeCNN은 2016년 van den Oord이 제안한 생성모델 입니다.(reference: [Conditional Image Generation with PixelCNN Decoders](https://arxiv.org/abs/1606.05328)).\n","이 모델은 이전 요소의 확률 분포가 이후 요소의 확률 분포를 나타내는 입력 벡터에서 반복적으로 이미지(또는 다른 데이터 타입)를 생성하도록 설계되었습니다. 다음 예에서 이미지는 이전에 생성된 픽셀(왼쪽 위)의 데이터만 보고 이후 픽셀을 생성하는 마스킹된 컨볼루션 커널을 통해 픽셀 단위로 생성됩니다. 추론하는 동안, 네트워크의 출력은 새로운 픽셀 값을 샘플링하여 새 영상을 생성하는 확률 분포로 사용됩니다(여기서 MNIST에서는 픽셀 값이 흰색(0)에서 검은색(255)."]},{"cell_type":"markdown","metadata":{"id":"sY0ipeUxAobZ"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"9SijQ0pO_XSN"},"source":[""]},{"cell_type":"code","metadata":{"id":"fQoaMVxQzdES"},"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tqdm import tqdm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":215},"id":"9V8wgOhN5KNz","executionInfo":{"status":"error","timestamp":1608377372487,"user_tz":-540,"elapsed":858,"user":{"displayName":"이든Eden","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3S9h8EstEhbK-5uVKGSPIF45b1jS21Bfc_kqVVg=s64","userId":"12301992914316596912"}},"outputId":"b589a96b-757f-4fdb-f403-dcde267a6589"},"source":["device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":null,"outputs":[{"output_type":"error","ename":"SystemError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-ce08ddae0a7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'/device:GPU:0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU device not found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Found GPU at: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mSystemError\u001b[0m: GPU device not found"]}]},{"cell_type":"markdown","metadata":{"id":"r3CadS8NzdET"},"source":["## 데이터 가져오기\n"]},{"cell_type":"code","metadata":{"id":"PeOHR78rzdET"},"source":["# Model / data parameters\n","num_classes = 10\n","input_shape = (28, 28, 1)\n","n_residual_blocks = 5\n","\n","# 데이터는 트레인, 테스트 셋으로 분리\n","# 보통은 아래와 같이 사용\n","# (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n","(x, _), (y, _) = keras.datasets.mnist.load_data()\n","\n","# 모든 이미지를 합칩니다.\n","data = np.concatenate((x, y), axis=0)\n","\n","# 모든 픽셀 값이 최대 256의 33% 미만일 경우 0으로 설정\n","# 이 값을 초과하는 모든 값은 1로 설정.\n","# 모든 값이 0 또는 1\n","data = np.where(data < (0.33 * 256), 0, 1)\n","data = data.astype(np.float32)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Z6xbto482h0","executionInfo":{"status":"ok","timestamp":1608363788086,"user_tz":-540,"elapsed":714,"user":{"displayName":"이든Eden","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3S9h8EstEhbK-5uVKGSPIF45b1jS21Bfc_kqVVg=s64","userId":"12301992914316596912"}},"outputId":"c56845e8-8b4a-4d52-929e-8777c2659ceb"},"source":["data[0].shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(28, 28)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"49Ojx0qbzdEU"},"source":["## 모델에 필요한 레이어에 클래스 두 개 만들기\n"]},{"cell_type":"code","metadata":{"id":"cmHRT-QEzdEU"},"source":["# 첫 번째 레이어는 PixelCNN 레이어 입니다. 이 레이어는 간단히\n","# 2D 컨볼루셔널 레이어로 만들어지지만, 마스킹을 포함합니다.\n","class PixelConvLayer(layers.Layer):\n","    def __init__(self, mask_type, **kwargs):\n","        super(PixelConvLayer, self).__init__()\n","        self.mask_type = mask_type\n","        self.conv = layers.Conv2D(**kwargs)\n","\n","    def build(self, input_shape):\n","        # 커널 변수를 초기화하기 위한 conv2d 레이어 만들기 \n","        self.conv.build(input_shape)\n","        # 마스크를 만들기 위해 초기화된 커널 사용 \n","        kernel_shape = self.conv.kernel.get_shape()\n","        self.mask = np.zeros(shape=kernel_shape)\n","        print(self.mask.shape)\n","        self.mask[: kernel_shape[0] // 2, ...] = 1.0\n","        self.mask[kernel_shape[0] // 2, : kernel_shape[1] // 2, ...] = 1.0\n","        if self.mask_type == \"B\":\n","            self.mask[kernel_shape[0] // 2, kernel_shape[1] // 2, ...] = 1.0\n","\n","    def call(self, inputs):\n","        self.conv.kernel.assign(self.conv.kernel * self.mask)\n","        return self.conv(inputs)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bgFNio0PK7QK","executionInfo":{"status":"ok","timestamp":1608367455525,"user_tz":-540,"elapsed":676,"user":{"displayName":"이든Eden","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3S9h8EstEhbK-5uVKGSPIF45b1jS21Bfc_kqVVg=s64","userId":"12301992914316596912"}},"outputId":"a76edbca-3478-4ff8-f4f8-2ee534db9a0c"},"source":["input_shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(28, 28, 1)"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"3YoHCR8m9Cjb"},"source":["# 다음은, 레지듀얼 블록 레이어를 만듭니다.\n","# 이것은 평범한 레지듀얼 블록이지만, PixelConvLayer에 기반합니다.\n","class ResidualBlock(keras.layers.Layer):\n","    def __init__(self, filters, **kwargs):\n","        super(ResidualBlock, self).__init__(**kwargs)\n","        self.conv1 = keras.layers.Conv2D(\n","            filters=filters, kernel_size=1, activation=\"relu\"\n","        )\n","        self.pixel_conv = PixelConvLayer(\n","            mask_type=\"B\",\n","            filters=filters // 2,\n","            kernel_size=3,\n","            activation=\"relu\",\n","            padding=\"same\",\n","        )\n","        self.conv2 = keras.layers.Conv2D(\n","            filters=filters, kernel_size=1, activation=\"relu\"\n","        )\n","\n","    def call(self, inputs):\n","        x = self.conv1(inputs)\n","        x = self.pixel_conv(x)\n","        x = self.conv2(x)\n","        return keras.layers.add([inputs, x])\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dcy857xnzdEU"},"source":["## 논문에 기반한 모델 만들기\n"]},{"cell_type":"code","metadata":{"id":"0a13hqFIzdEV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608373232466,"user_tz":-540,"elapsed":2654953,"user":{"displayName":"이든Eden","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3S9h8EstEhbK-5uVKGSPIF45b1jS21Bfc_kqVVg=s64","userId":"12301992914316596912"}},"outputId":"90e55a88-a7a3-4d21-bb2c-74286ddeb54d"},"source":["inputs = keras.Input(shape=input_shape)\n","x = PixelConvLayer(\n","    mask_type=\"A\", filters=128, kernel_size=7, activation=\"relu\", padding=\"same\"\n",")(inputs)\n","\n","for _ in range(n_residual_blocks):\n","    x = ResidualBlock(filters=128)(x)\n","\n","for _ in range(2):\n","    x = PixelConvLayer(\n","        mask_type=\"B\",\n","        filters=128,\n","        kernel_size=1,\n","        strides=1,\n","        activation=\"relu\",\n","        padding=\"valid\",\n","    )(x)\n","\n","out = keras.layers.Conv2D(\n","    filters=1, kernel_size=1, strides=1, activation=\"sigmoid\", padding=\"valid\"\n",")(x)\n","\n","pixel_cnn = keras.Model(inputs, out)\n","adam = keras.optimizers.Adam(learning_rate=0.0005)\n","with tf.device('/gpu:0'):\n","  pixel_cnn.compile(optimizer=adam, loss=\"binary_crossentropy\")\n","  pixel_cnn.summary()\n","  pixel_cnn.fit(\n","      x=data, y=data, batch_size=128, epochs=50, validation_split=0.1, verbose=2\n","  )\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(7, 7, 1, 128)\n","(3, 3, 128, 64)\n","(3, 3, 128, 64)\n","(3, 3, 128, 64)\n","(3, 3, 128, 64)\n","(3, 3, 128, 64)\n","(1, 1, 128, 128)\n","(1, 1, 128, 128)\n","Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_5 (InputLayer)         [(None, 28, 28, 1)]       0         \n","_________________________________________________________________\n","pixel_conv_layer_11 (PixelCo (None, 28, 28, 128)       6400      \n","_________________________________________________________________\n","residual_block_5 (ResidualBl (None, 28, 28, 128)       98624     \n","_________________________________________________________________\n","residual_block_6 (ResidualBl (None, 28, 28, 128)       98624     \n","_________________________________________________________________\n","residual_block_7 (ResidualBl (None, 28, 28, 128)       98624     \n","_________________________________________________________________\n","residual_block_8 (ResidualBl (None, 28, 28, 128)       98624     \n","_________________________________________________________________\n","residual_block_9 (ResidualBl (None, 28, 28, 128)       98624     \n","_________________________________________________________________\n","pixel_conv_layer_17 (PixelCo (None, 28, 28, 128)       16512     \n","_________________________________________________________________\n","pixel_conv_layer_18 (PixelCo (None, 28, 28, 128)       16512     \n","_________________________________________________________________\n","conv2d_40 (Conv2D)           (None, 28, 28, 1)         129       \n","=================================================================\n","Total params: 532,673\n","Trainable params: 532,673\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/50\n","493/493 - 61s - loss: 0.1171 - val_loss: 0.0953\n","Epoch 2/50\n","493/493 - 53s - loss: 0.0919 - val_loss: 0.0905\n","Epoch 3/50\n","493/493 - 53s - loss: 0.0896 - val_loss: 0.0899\n","Epoch 4/50\n","493/493 - 53s - loss: 0.0885 - val_loss: 0.0879\n","Epoch 5/50\n","493/493 - 53s - loss: 0.0877 - val_loss: 0.0899\n","Epoch 6/50\n","493/493 - 53s - loss: 0.0872 - val_loss: 0.0870\n","Epoch 7/50\n","493/493 - 53s - loss: 0.0867 - val_loss: 0.0871\n","Epoch 8/50\n","493/493 - 53s - loss: 0.0862 - val_loss: 0.0862\n","Epoch 9/50\n","493/493 - 53s - loss: 0.0859 - val_loss: 0.0864\n","Epoch 10/50\n","493/493 - 53s - loss: 0.0856 - val_loss: 0.0855\n","Epoch 11/50\n","493/493 - 53s - loss: 0.0853 - val_loss: 0.0854\n","Epoch 12/50\n","493/493 - 53s - loss: 0.0851 - val_loss: 0.0856\n","Epoch 13/50\n","493/493 - 53s - loss: 0.0849 - val_loss: 0.0848\n","Epoch 14/50\n","493/493 - 53s - loss: 0.0846 - val_loss: 0.0848\n","Epoch 15/50\n","493/493 - 53s - loss: 0.0844 - val_loss: 0.0849\n","Epoch 16/50\n","493/493 - 53s - loss: 0.0842 - val_loss: 0.0849\n","Epoch 17/50\n","493/493 - 53s - loss: 0.0841 - val_loss: 0.0846\n","Epoch 18/50\n","493/493 - 53s - loss: 0.0840 - val_loss: 0.0845\n","Epoch 19/50\n","493/493 - 53s - loss: 0.0838 - val_loss: 0.0850\n","Epoch 20/50\n","493/493 - 53s - loss: 0.0837 - val_loss: 0.0842\n","Epoch 21/50\n","493/493 - 53s - loss: 0.0835 - val_loss: 0.0842\n","Epoch 22/50\n","493/493 - 53s - loss: 0.0834 - val_loss: 0.0839\n","Epoch 23/50\n","493/493 - 53s - loss: 0.0833 - val_loss: 0.0839\n","Epoch 24/50\n","493/493 - 53s - loss: 0.0832 - val_loss: 0.0838\n","Epoch 25/50\n","493/493 - 53s - loss: 0.0831 - val_loss: 0.0837\n","Epoch 26/50\n","493/493 - 53s - loss: 0.0830 - val_loss: 0.0838\n","Epoch 27/50\n","493/493 - 53s - loss: 0.0829 - val_loss: 0.0837\n","Epoch 28/50\n","493/493 - 53s - loss: 0.0828 - val_loss: 0.0837\n","Epoch 29/50\n","493/493 - 53s - loss: 0.0827 - val_loss: 0.0839\n","Epoch 30/50\n","493/493 - 53s - loss: 0.0826 - val_loss: 0.0836\n","Epoch 31/50\n","493/493 - 53s - loss: 0.0825 - val_loss: 0.0835\n","Epoch 32/50\n","493/493 - 53s - loss: 0.0825 - val_loss: 0.0835\n","Epoch 33/50\n","493/493 - 53s - loss: 0.0824 - val_loss: 0.0835\n","Epoch 34/50\n","493/493 - 53s - loss: 0.0824 - val_loss: 0.0838\n","Epoch 35/50\n","493/493 - 53s - loss: 0.0823 - val_loss: 0.0833\n","Epoch 36/50\n","493/493 - 53s - loss: 0.0822 - val_loss: 0.0834\n","Epoch 37/50\n","493/493 - 53s - loss: 0.0821 - val_loss: 0.0832\n","Epoch 38/50\n","493/493 - 53s - loss: 0.0820 - val_loss: 0.0840\n","Epoch 39/50\n","493/493 - 53s - loss: 0.0820 - val_loss: 0.0832\n","Epoch 40/50\n","493/493 - 53s - loss: 0.0819 - val_loss: 0.0835\n","Epoch 41/50\n","493/493 - 53s - loss: 0.0818 - val_loss: 0.0837\n","Epoch 42/50\n","493/493 - 53s - loss: 0.0818 - val_loss: 0.0832\n","Epoch 43/50\n","493/493 - 53s - loss: 0.0817 - val_loss: 0.0834\n","Epoch 44/50\n","493/493 - 53s - loss: 0.0817 - val_loss: 0.0831\n","Epoch 45/50\n","493/493 - 53s - loss: 0.0816 - val_loss: 0.0831\n","Epoch 46/50\n","493/493 - 53s - loss: 0.0816 - val_loss: 0.0835\n","Epoch 47/50\n","493/493 - 53s - loss: 0.0815 - val_loss: 0.0833\n","Epoch 48/50\n","493/493 - 53s - loss: 0.0815 - val_loss: 0.0832\n","Epoch 49/50\n","493/493 - 53s - loss: 0.0814 - val_loss: 0.0835\n","Epoch 50/50\n","493/493 - 53s - loss: 0.0814 - val_loss: 0.0831\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"m0GCMXV8zdEV"},"source":["## 해보기\n","\n","PixelCNN은 이미지 전체를 한 번에 생성하지 못합니다. 대신 각 픽셀을 순서대로 생성하고 마지막으로 생성된 픽셀을 현재 이미지 추가한 다음, 이미지를 다시 모델에 공급하여 프로세스를 반복해야 합니다.\n"]},{"cell_type":"code","metadata":{"id":"Cm12F9vHT4kX","colab":{"base_uri":"https://localhost:8080/","height":215},"executionInfo":{"status":"error","timestamp":1608377360599,"user_tz":-540,"elapsed":749,"user":{"displayName":"이든Eden","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3S9h8EstEhbK-5uVKGSPIF45b1jS21Bfc_kqVVg=s64","userId":"12301992914316596912"}},"outputId":"f53a1de3-da91-4417-bb93-3b2998daec35"},"source":["from IPython.display import Image, display\n","\n","# Create an empty array of pixels.\n","# 픽셀의 빈 배열 만들기\n","batch = 4\n","pixels = np.zeros(shape=(batch,) + (pixel_cnn.input_shape)[1:])\n","batch, rows, cols, channels = pixels.shape"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-5ed80a57db87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 픽셀의 빈 배열 만들기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpixels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpixel_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpixels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hZqQJu9CUVq9","executionInfo":{"status":"ok","timestamp":1608369933590,"user_tz":-540,"elapsed":939,"user":{"displayName":"이든Eden","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3S9h8EstEhbK-5uVKGSPIF45b1jS21Bfc_kqVVg=s64","userId":"12301992914316596912"}},"outputId":"c885f25e-274f-4405-92ef-08878704c4df"},"source":["(pixel_cnn.input_shape)[1:]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(28, 28, 1)"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wT5LTtlwUb06","executionInfo":{"status":"ok","timestamp":1608369950485,"user_tz":-540,"elapsed":805,"user":{"displayName":"이든Eden","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3S9h8EstEhbK-5uVKGSPIF45b1jS21Bfc_kqVVg=s64","userId":"12301992914316596912"}},"outputId":"fc09bf72-4041-4bfe-9b10-24f1d4da5a9a"},"source":["pixels.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4, 28, 28, 1)"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1pbgDdLNvDj9","executionInfo":{"status":"ok","timestamp":1608377039701,"user_tz":-540,"elapsed":736,"user":{"displayName":"이든Eden","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3S9h8EstEhbK-5uVKGSPIF45b1jS21Bfc_kqVVg=s64","userId":"12301992914316596912"}},"outputId":"10e8df8f-776a-47f8-d740-a0b76fae453b"},"source":["tf.random.uniform((1, 5))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n","array([[0.7618835 , 0.3667817 , 0.25058377, 0.74013364, 0.35321212]],\n","      dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":63}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"_dCywwdcj3Qu","executionInfo":{"status":"error","timestamp":1608376916411,"user_tz":-540,"elapsed":10545,"user":{"displayName":"이든Eden","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3S9h8EstEhbK-5uVKGSPIF45b1jS21Bfc_kqVVg=s64","userId":"12301992914316596912"}},"outputId":"f43656c4-9a8d-41e5-d367-11c07769c5b3"},"source":["from IPython.display import Image, display\n","\n","# Create an empty array of pixels.\n","# 픽셀의 빈 배열 만들기\n","batch = 4\n","pixels = np.zeros(shape=(batch,) + (pixel_cnn.input_shape)[1:])\n","batch, rows, cols, channels = pixels.shape\n","\n","# Iterate over the pixels because generation has to be done sequentially pixel by pixel.\n","# 생성은 픽셀 단위로 순차적으로 수행되기 때문에 픽셀에 대해 반복됩니다.\n","for row in tqdm(range(rows)):\n","    for col in range(cols):\n","        for channel in range(channels):\n","            # 전체 배열 피딩하고(feed) 다음 픽셀에 대한 픽셀 값 확률 탐\n","            probs = pixel_cnn.predict(pixels)[:, row, col, channel]\n","            # 확률을 사용하여 픽셀 값을 선택하고, 선택한 값을 이미지 프레임에 추가\n","            pixels[:, row, col, channel] = tf.math.ceil(\n","                probs - tf.random.uniform(probs.shape)\n","            )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","  4%|▎         | 1/28 [00:00<00:24,  1.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","  7%|▋         | 2/28 [00:01<00:23,  1.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n"," 11%|█         | 3/28 [00:02<00:22,  1.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n"," 14%|█▍        | 4/28 [00:03<00:21,  1.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n"," 18%|█▊        | 5/28 [00:04<00:20,  1.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n"," 21%|██▏       | 6/28 [00:05<00:19,  1.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n"," 25%|██▌       | 7/28 [00:06<00:18,  1.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n"," 29%|██▊       | 8/28 [00:07<00:17,  1.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n"," 32%|███▏      | 9/28 [00:08<00:17,  1.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n"," 36%|███▌      | 10/28 [00:08<00:16,  1.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2530\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2531\u001b[0;31m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2532\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Operation 'Identity' has no attr named '_read_only_resource_inputs'.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-60-709d6e9f12ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mchannel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;31m# 전체 배열 피딩하고(feed) 다음 픽셀에 대한 픽셀 값 확률 탐\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpixel_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0;31m# 확률을 사용하여 픽셀 값을 선택하고, 선택한 값을 이미지 프레임에 추가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             pixels[:, row, col, channel] = tf.math.ceil(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1606\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1608\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mslice_inputs\u001b[0;34m(self, indices_dataset, inputs)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     dataset = dataset.map(\n\u001b[0;32m--> 388\u001b[0;31m         grab_batch, num_parallel_calls=dataset_ops.AUTOTUNE)\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;31m# Default optimizations are disabled to avoid the overhead of (unnecessary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1810\u001b[0m           \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1811\u001b[0m           \u001b[0mdeterministic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1812\u001b[0;31m           preserve_cardinality=True)\n\u001b[0m\u001b[1;32m   1813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1814\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   4244\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4245\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4246\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   4247\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdeterministic\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4248\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deterministic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"default\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3523\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3524\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3525\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3527\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3050\u001b[0m     \"\"\"\n\u001b[1;32m   3051\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 3052\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   3053\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3054\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3017\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3018\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3019\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3020\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m       captured = object_identity.ObjectIdentitySet(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   1029\u001b[0m         if x is not None)\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m     \u001b[0mfunc_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0madd_control_dependencies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/auto_control_deps.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, unused_type, unused_value, unused_traceback)\u001b[0m\n\u001b[1;32m    407\u001b[0m       \u001b[0;31m# Check for any resource inputs. If we find any, we update control_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m       \u001b[0;31m# and last_write_to_resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_get_resource_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         \u001b[0mis_read\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresource_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mResourceType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_ONLY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0minput_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/auto_control_deps.py\u001b[0m in \u001b[0;36m_get_resource_inputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_resource_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m   \u001b[0;34m\"\"\"Returns an iterable of resources touched by this `op`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m   \u001b[0mreads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrites\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_read_write_resource_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m   \u001b[0msaturated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msaturated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/auto_control_deps_utils.py\u001b[0m in \u001b[0;36mget_read_write_resource_inputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mread_only_input_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mREAD_ONLY_RESOURCE_INPUTS_ATTR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;31m# Attr was not set. Add all resource inputs to `writes` and return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2529\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2530\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2531\u001b[0;31m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2532\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2533\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"lZT7W3fszdEW","colab":{"base_uri":"https://localhost:8080/","height":232},"executionInfo":{"status":"error","timestamp":1608377276655,"user_tz":-540,"elapsed":1810,"user":{"displayName":"이든Eden","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3S9h8EstEhbK-5uVKGSPIF45b1jS21Bfc_kqVVg=s64","userId":"12301992914316596912"}},"outputId":"4a189bab-66c0-4e38-8840-fc51b7dd8df9"},"source":["from IPython.display import Image, display\n","\n","# Create an empty array of pixels.\n","# 픽셀의 빈 배열 만들기\n","batch = 4\n","pixels = np.zeros(shape=(batch,) + (pixel_cnn.input_shape)[1:])\n","batch, rows, cols, channels = pixels.shape\n","\n","# Iterate over the pixels because generation has to be done sequentially pixel by pixel.\n","# 생성은 픽셀 단위로 순차적으로 수행되기 때문에 픽셀에 대해 반복됩니다.\n","for row in tqdm(range(rows)):\n","    for col in range(cols):\n","        for channel in range(channels):\n","            # 전체 배열 피딩하고(feed) 다음 픽셀에 대한 픽셀 값 확률 탐\n","            probs = pixel_cnn.predict(pixels)[:, row, col, channel]\n","            # 확률을 사용하여 픽셀 값을 선택하고, 선택한 값을 이미지 프레임에 추가\n","            pixels[:, row, col, channel] = tf.math.ceil(\n","                probs - tf.random.uniform(probs.shape)\n","            )\n","\n","\n","def deprocess_image(x):\n","    # 단일 채널화된 흑백 이미지를 RGB 값으로 쌓습니다(stack).\n","    x = np.stack((x, x, x), 2)\n","    # 전처리 돌려놓기\n","    x *= 255.0\n","    # uint8로 변환하고 유효한 범위인 [0, 255]로 클립합니다 \n","    x = np.clip(x, 0, 255).astype(\"uint8\")\n","    return x\n","\n","\n","# 생성 된 이미지를 반복하고 matplotlib로 플로팅합니다.\n","for i, pic in enumerate(pixels):\n","    keras.preprocessing.image.save_img(\n","        \"generated_image_{}.png\".format(i), deprocess_image(np.squeeze(pic, -1))\n","    )\n","\n","display(Image(\"generated_image_0.png\"))\n","display(Image(\"generated_image_1.png\"))\n","display(Image(\"generated_image_2.png\"))\n","display(Image(\"generated_image_3.png\"))\n"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-4020e89fae35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 픽셀의 빈 배열 만들기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpixels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpixel_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpixels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"]}]}]}